{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:34:26.823471Z","iopub.status.idle":"2025-01-09T08:34:26.833071Z","shell.execute_reply.started":"2025-01-09T08:34:26.823822Z","shell.execute_reply":"2025-01-09T08:34:26.831231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:34:26.834863Z","iopub.execute_input":"2025-01-09T08:34:26.835254Z","iopub.status.idle":"2025-01-09T08:34:26.856145Z","shell.execute_reply.started":"2025-01-09T08:34:26.835221Z","shell.execute_reply":"2025-01-09T08:34:26.854958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\nprint(data_train.shape)\n\ndata_val = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\nprint(data_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:34:26.858254Z","iopub.execute_input":"2025-01-09T08:34:26.858554Z","iopub.status.idle":"2025-01-09T08:34:26.917935Z","shell.execute_reply.started":"2025-01-09T08:34:26.858528Z","shell.execute_reply":"2025-01-09T08:34:26.916727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(data_train, data_val):\n    # Clearing\n    label = \"SalePrice\"\n    target = data_train[label]\n    data_train = data_train.drop([label], axis=1)\n\n    data = pd.concat([data_train, data_val])\n    features = data.drop([\"Id\"], axis=1)\n\n    # Normalization \n    num_features_names = features.dtypes[features.dtypes != \"O\"].index\n    features[num_features_names] = (features[num_features_names] - features[num_features_names].mean()) / features[num_features_names].std()\n\n    \n    data_train_clean, data_val_clean = features[:data_train.shape[0]], features[data_train.shape[0]:]\n    data_train_clean.loc[:, num_features_names] = data_train_clean[num_features_names].fillna(data_train_clean[num_features_names].mean())\n    \n    return pd.concat([target, data_train_clean], axis=1), data_val_clean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:34:26.919315Z","iopub.execute_input":"2025-01-09T08:34:26.919775Z","iopub.status.idle":"2025-01-09T08:34:26.926509Z","shell.execute_reply.started":"2025-01-09T08:34:26.919744Z","shell.execute_reply":"2025-01-09T08:34:26.925316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_train_norm, data_val_norm = preprocess(data_train, data_val) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_features_names = data_train.dtypes[data_train.dtypes == \"O\"].index\n\nfor feature in cat_features_names:\n    data_train_norm[feature].fillna(\"nan\", inplace=True)\n    data_val_norm[feature].fillna(\"nan\", inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, y_train = data_train_norm.drop([\"SalePrice\"], axis=1), np.log(data_train_norm[\"SalePrice\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nval_errors = []\ntrain_errors = []\n\nfor train_index, val_index in tqdm(kf.split(X_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n\n    model = CatBoostRegressor(iterations=300,\n                         depth=8,\n                         loss_function=\"RMSE\",\n                         cat_features=cat_features_names.tolist(),\n                         nan_mode='Min',\n                         verbose=0)\n\n    model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold))\n    \n    evals_result = model.get_evals_result()\n    train_loss = evals_result[\"learn\"][\"RMSE\"]\n    train_errors.append(train_loss)\n\n    y_val_pred = model.predict(X_val_fold)\n\n    val_rmse = np.sqrt(np.mean((y_val_fold - y_val_pred) ** 2))\n    val_errors.append(val_rmse)\nprint(f\"Average RMSE: {np.mean(val_errors)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.scatter(range(len(val_errors)), val_errors, c=\"orange\")\nplt.xlabel(\"Number of fold\")\nplt.ylabel(\"Loss (RMSE)\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_loss = np.mean(np.dstack(train_errors)[0], axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(range(len(mean_loss)), mean_loss, c=\"orange\", label=\"Train loss\")\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Loss (RMSE)\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = CatBoostRegressor(iterations=300,\n                     depth=10,\n                     loss_function=\"RMSE\",\n                    cat_features=cat_features_names.tolist(),\n                     nan_mode='Min',\n                     verbose=0)\n\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loss = model.get_evals_result()[\"learn\"][\"RMSE\"]\n\nplt.figure(figsize=(10, 6))\nplt.plot(range(len(train_loss)), train_loss, c=\"orange\", label=\"Train loss\")\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Loss (RMSE)\")\nplt.title(\"Train Loss\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\n\nfeats_importance = pd.DataFrame({\"Importance\": model.feature_importances_, \n                                 \"Feat_Name\": X_train.columns}).sort_values(by=\"Importance\", ascending=False)\n\nplt.figure(figsize=(10,6))\nsns.barplot(x=\"Importance\", y=\"Feat_Name\",\n            data=feats_importance[:10],\n            palette=\"icefire_r\")\nplt.title(\"Feature Importances\")\nplt.xlabel(\"Feature Importance\")\nplt.ylabel(\"Feature name\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\n\nshap.initjs()\n\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer(X_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shap.summary_plot(shap_values, X_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = np.exp(model.predict(data_val_norm))\n\ndata_submission = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\")\nnp.sqrt(np.mean((data_submission[\"SalePrice\"] - y_pred) ** 2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_submission[\"SalePrice\"] = y_pred\ndata_submission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}